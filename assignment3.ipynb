{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "287bb0d5-d677-4273-8945-1ebffb79f21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.142587Z",
     "start_time": "2025-10-25T11:09:09.138603Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"assignment_3_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01a788-005c-4cf6-8602-5ab6c6cf2813",
   "metadata": {},
   "source": [
    "## Cleaning and normalization \n",
    "---\n",
    "- The caps column contained ambiguous entries (e.g., \"??\" and empty fields), which were normalized to the value \"not answered\" for consistency.\n",
    "- Inconsistencies in the lang column such as variations in capitalization were standardized.\n",
    "- Empty cells across the dataset were replaced with \"not answered\" where appropriate to maintain data completeness without introducing incorrect numeric assumptions.\n",
    "- All relevant numerical variables were converted to floating-point format to ensure consistent data types and enable accurate statistical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac467ad99b9192d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.190792Z",
     "start_time": "2025-10-25T11:09:09.187813Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    df[c] = df[c].replace(('','??'), np.nan).fillna(\"not answered\")\n",
    "\n",
    "# 2.Lang has spelling inconsistencies \n",
    "\n",
    "df['lang'] = df['lang'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "547da149-a4d4-4af1-bfe2-3ad20900c131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.313032Z",
     "start_time": "2025-10-25T11:09:09.310535Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert all ints to floats to make it easier to handle\n",
    "for c in df.columns:\n",
    "    df[c] = df[c].apply(lambda x: float(x) if isinstance(x, int) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dc24a1ff-f05c-4399-afed-3c47de0b5378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.365694Z",
     "start_time": "2025-10-25T11:09:09.362313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years coding: 16.65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#For each with excessive whours they have the same amount in stmL\n",
    "df['stmtL'] = pd.to_numeric(df['stmtL'], errors='coerce')\n",
    "df['whours'] = pd.to_numeric(df['whours'], errors='coerce')\n",
    "# Pick these and list them\n",
    "\n",
    "outliers = df[\n",
    "    (df[\"stmtL\"] == df[\"whours\"]) &\n",
    "    (df[\"stmtL\"] >= 34632)\n",
    "]\n",
    "print(\"Years coding:\", (34632 / 40) / 52)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a6dea94-ea15-422f-a2fa-772a01b8deef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:22:59.980531Z",
     "start_time": "2025-10-24T15:22:59.960542Z"
    }
   },
   "source": [
    "**Motivation**\n",
    "Upon examining the data, several entries contain extremely high values for both stmtL (lines of code) and whours (work hours). For example, participant s149401 reports 34,632 work hours and the same number of lines of code. Assuming a typical full-time workload of approximately 2,000 hours per year (40 hours/week Ã— 52 weeks), this would correspond to more than 16 years of continuous full-time development on the same task. This scenario is incompatible with the experimental context of the dataset, where productivity was measured in a controlled study rather than across decades of professional work.\n",
    "\n",
    "These observations are therefore considered implausible measurement errors. To prevent distortion of statistical summaries and visualizations, entries exceeding the largest plausible observation (34,632) were excluded for both variables (whours and stmtL) using a single consistent threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "32257b5703fe8396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.473695Z",
     "start_time": "2025-10-25T11:09:09.470904Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['stmtL'] >= 34632].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53961a1-db03-4727-9bdb-55e9b427745e",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "063322e7-433b-4ed8-8698-33d2d8b25137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:39.713808Z",
     "start_time": "2025-10-25T11:09:39.707360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stmtL_temp</th>\n",
       "      <th>whours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>9.300000</td>\n",
       "      <td>9.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>11.420000</td>\n",
       "      <td>11.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>15.572727</td>\n",
       "      <td>15.572727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perl</th>\n",
       "      <td>3.378462</td>\n",
       "      <td>3.378462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>3.205000</td>\n",
       "      <td>3.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rexx</th>\n",
       "      <td>5.482500</td>\n",
       "      <td>5.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tcl</th>\n",
       "      <td>4.716250</td>\n",
       "      <td>4.716250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stmtL_temp     whours\n",
       "lang                         \n",
       "C         9.300000   9.300000\n",
       "C++      11.420000  11.420000\n",
       "Java     15.572727  15.572727\n",
       "Perl      3.378462   3.378462\n",
       "Python    3.205000   3.205000\n",
       "Rexx      5.482500   5.482500\n",
       "Tcl       4.716250   4.716250"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stmtL_temp'] = pd.to_numeric(df['stmtL'], errors='coerce')\n",
    "\n",
    "# Group by language and calculate the mean\n",
    "lang_summary = df.groupby('lang')[['stmtL_temp', 'whours']].mean()\n",
    "\n",
    "lang_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e0f1e05985141ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:10:59.036960Z",
     "start_time": "2025-10-25T11:10:58.984903Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['stmtL_temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f965ac9-f607-4611-8c01-e171210e78a8",
   "metadata": {},
   "source": [
    "This visualization presents the average number of lines of code and the average working hours for each programming language. The results indicate that Java and TCL exhibit notably higher values in both metrics, suggesting that programs written in these languages required more development effort and produced larger code bases. Additionally, the trend across languages aligns with the overall correlation observed between lines of code and working hours, where increased code size is associated with greater time investment.\n",
    "\n",
    "A potential bias in the data is that all subjects appear to produce code at an identical rate of one line of code per hour, regardless of programming language or individual differences. This uniform productivity pattern is highly improbable in practice and likely indicates a data collection or recording error. As a result, conclusions involving productivity should be interpreted with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f0085c518a147a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.717882Z",
     "start_time": "2025-10-25T11:06:43.645437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z1000t_temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>5.429250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C++</th>\n",
       "      <td>2.974182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Java</th>\n",
       "      <td>4.937182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perl</th>\n",
       "      <td>7.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>6.434667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rexx</th>\n",
       "      <td>15.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tcl</th>\n",
       "      <td>26.326000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        z1000t_temp\n",
       "lang               \n",
       "C          5.429250\n",
       "C++        2.974182\n",
       "Java       4.937182\n",
       "Perl       7.625000\n",
       "Python     6.434667\n",
       "Rexx      15.739000\n",
       "Tcl       26.326000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['z1000t_temp'] = pd.to_numeric(df['z1000t'], errors='coerce')\n",
    "# Group by language and calculate the mean\n",
    "speed_sum = df.groupby('lang')[['z1000t_temp']].mean()\n",
    "\n",
    "df = df.drop(columns=['z1000t_temp'])\n",
    "\n",
    "speed_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2608a4-f796-43c3-ba8e-11d644153fbc",
   "metadata": {},
   "source": [
    "The table displays the average runtime for each programming language using the z1000 input. The results indicate that lower-level compiled languages such as C++ and C achieve the shortest execution times, while interpreted languages such as Tcl and Rexx show substantially longer runtimes. This suggests that compiled languages in this dataset generally exhibit higher performance efficiency compared to interpreted languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9affe6fe-c5a1-4b7f-9fba-502312f7fd58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.721035Z",
     "start_time": "2025-10-25T11:00:25.790035Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['stmtL', 'whours']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554eadd74f9469e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.722747Z",
     "start_time": "2025-10-25T11:00:25.868215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to numeric, invalid entries become NaN\n",
    "df['z1000mem'] = pd.to_numeric(df['z1000mem'], errors='coerce')\n",
    "\n",
    "#Mean, median, max memory usage per language\n",
    "memory_summary = df.groupby('lang')['z1000mem'].agg(['mean', 'median', 'max','min', 'count']).sort_values('mean', ascending=False)\n",
    "memory_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e5647-d52d-454c-8fc1-4f2a5fe69916",
   "metadata": {},
   "source": [
    "Based on these variables C++ memory usage in both mean and median however it has the relativly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143274ac-2d05-4c1f-bcf8-9ce3a3771c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total reliability as a simple sum of z1000rel + m1000rel\n",
    "df['total_rel'] = df['z1000rel'] + df['m1000rel']\n",
    "\n",
    "\n",
    "# Group by programming language and calculate average total reliability\n",
    "lang_performance = (df.groupby('lang')['total_rel'].mean().sort_values(ascending=False)/2)\n",
    "\n",
    "print(\"Average total reliability by language: (out of 100%)\")\n",
    "lang_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a2a3c-7b07-4250-8a1e-c7bb60a817e6",
   "metadata": {},
   "source": [
    "## Correlation Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8537481-7295-4dd4-bd07-663fc7938409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.726509Z",
     "start_time": "2025-10-25T11:00:25.916221Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cols = ['stmtL', 'whours', 'z1000t', 'z1000mem']\n",
    "\n",
    "# Convert all to numeric; non-numeric entries become NaN\n",
    "numeric_df = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute correlation\n",
    "corr = numeric_df.corr(method='pearson')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr, annot=True, cmap='YlGnBu', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6e5b9-0a9f-4689-af19-64aef10f8d54",
   "metadata": {},
   "source": [
    "| Pearson correlation coefficient (r) value | Strength  | Direction |\n",
    "|--------------------------------------------|------------|------------|\n",
    "| Greater than .5                            | Strong     | Positive   |\n",
    "| Between .3 and .5                          | Moderate   | Positive   |\n",
    "| Between 0 and .3                           | Weak       | Positive   |\n",
    "| 0                                          | None       | None       |\n",
    "| Between 0 and â€“.3                          | Weak       | Negative   |\n",
    "| Between â€“.3 and â€“.5                        | Moderate   | Negative   |\n",
    "| Less than â€“.5                              | Strong     | Negative   |\n",
    "\n",
    "- Based on the above table we can see that for both heat maps there is a strong correlation between whours and stmtL.\n",
    "- Other correlation in both cases are weak. With the difference with the outliers filtered the weak positive correlation become weak negative ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74a209-a4e5-43cc-a7a2-6defd4508e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation betweeb high reliablity and caps\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "valid_caps = ['0-10%', '10-25%', '25-40%', '40-60%', '60-75%']\n",
    "df_caps = df[df['caps'].isin(valid_caps)].copy()\n",
    "\n",
    "order = {'0-10%': 1, '10-25%': 2, '25-40%': 3, '40-60%': 4, '60-75%': 5}\n",
    "df_caps['caps_encoded'] = df_caps['caps'].map(order)\n",
    "\n",
    "# Convert reliability to numeric\n",
    "df_caps['m1000rel'] = pd.to_numeric(df_caps['m1000rel'], errors='coerce')\n",
    "\n",
    "# Drop missing reliability values\n",
    "df_caps = df_caps.dropna(subset=['m1000rel'])\n",
    "\n",
    "# Spearman correlation\n",
    "r, p = spearmanr(df_caps['caps_encoded'], df_caps['m1000rel'])\n",
    "\n",
    "print(f\"Spearman correlation: r = {r:.3f}, p = {p:.3f}\")\n",
    "print(f\"Sample size: {len(df_caps)}\")\n",
    "\n",
    "\n",
    "sns.regplot(\n",
    "    data=df_caps,\n",
    "    x='caps_encoded',\n",
    "    y='m1000rel',\n",
    "    logistic=False,\n",
    "    scatter_kws={'alpha':0.7}\n",
    ")\n",
    "plt.xticks(ticks=[1,2,3,4,5], labels=valid_caps)\n",
    "plt.xlabel(\"Self-rated programmer capability\")\n",
    "plt.ylabel(\"Reliability score (m1000rel)\")\n",
    "plt.title(\"Spearman correlation: Capability vs Reliability\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cfb2dc-7e17-484e-a563-6c42635e30f9",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "---\n",
    "#### Hypothesis \n",
    "1. The more lines of code the more working hours are spent.\n",
    "2. The longer the runtime, the more memory consumption the program requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a36bd0-11ff-4d87-b577-a9ecd47289f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T11:09:09.727475Z",
     "start_time": "2025-10-25T11:00:26.036190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hypothesis 1\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "cols = ['stmtL', 'whours']\n",
    "\n",
    "# Make selected columns numeric; non-numeric -> NaN\n",
    "numeric_df = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in either column (keeps indices aligned)\n",
    "clean_df = numeric_df.dropna()\n",
    "\n",
    "pearson_corr, p_val = pearsonr(clean_df['stmtL'], clean_df['whours'])\n",
    "print(f\"Pearson r = {pearson_corr:.3f}, p-value = {p_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda6568-ba54-43c8-90c7-77ce59836b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick and adjust data\n",
    "df['z1000t'] = pd.to_numeric(df['z1000t'], errors='coerce')\n",
    "df['z1000mem'] = pd.to_numeric(df['z1000mem'], errors='coerce')\n",
    "\n",
    "df_clean = df.dropna(subset=['z1000t', 'z1000mem'])\n",
    "\n",
    "r, p = pearsonr(df_clean['z1000t'], df_clean['z1000mem'])\n",
    "\n",
    "print(f\"Pearson correlation: r = {r:.3f}, p = {p:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf6b1a-5d98-4c8c-9203-c002197d2d78",
   "metadata": {},
   "source": [
    "**Claim: The more lines of code, the more working hours are spent.**\n",
    "\n",
    "- HO:There is no correlation between lines of code (stmtL) and working hours (whours).\n",
    "- H1:There is a positive correlation â€” more lines of code â†’ more hours worked.\n",
    "\n",
    "Analysis output: Pearson r = 1.000, p-value = 0.000\n",
    "\n",
    "r = 1.000 which shows a perfect *positive* correlation. This means that as the number of lines of code increases, working hours increas in an almost a perfect linear way. \n",
    "since p < 0.05 the resuls is statistically significant. \n",
    "\n",
    "**Conclusion**: Reject H0.\n",
    "There is strong evidence of a perfect positive relationship between lines of code and working hours. In other words, programmers who write more lines of code also spend more time coding. \n",
    "\n",
    "---\n",
    "\n",
    "**Claim: The longer the runtime, the more memory consumption the program requires.**\n",
    "\n",
    "- H0: There is no relationship between runtime (z1000t) and memory consumption (z1000mem).\n",
    "- H1: Runtime (z1000t) is positively correlated with memory consumption (z1000mem).\n",
    "\n",
    "Analysis output: Pearson correlation: r = 0.073, p = 0.540\n",
    "\n",
    "**r-value:** shows that there is a very small correlation.\n",
    "**p-value:** Shows there is no statistical signifcance.\n",
    "\n",
    "**Conclusion**: **fail** to reject H0. \n",
    "The correlation between runtime and memory is very weak therefore we can conclude there is no supporting evidence that programs with longer runtime consume more memory.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda444bf-4660-4204-9ff9-0e4a6ba2904b",
   "metadata": {},
   "source": [
    "## Visualization & Reporting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e485f2-150f-4bd8-a929-7c18ef4d8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean, x='whours', y='stmtL')\n",
    "plt.xlabel(\"Work hours\")\n",
    "plt.ylabel(\"Lines of code\")\n",
    "plt.title(\"Relationship between work hours and code written\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891815a1-8d70-41c2-aa01-62d78ed7b0c0",
   "metadata": {},
   "source": [
    "### Discussing Hypothesis One\n",
    "\n",
    "**The more lines of code, the more working hours are spent.**\n",
    "\n",
    "The data analysis indicates a perfect positive correlation between the number of lines of code and the total working hours. However, this relationship is unlikely to reflect real-world productivity. The dataset shows that, for every participant, the reported number of lines of code is exactly equal to the number of hours worked. This implies that every subject wrote code at a constant pace of one line per hour, which is highly unrealistic across multiple individuals and programming tasks.\n",
    "\n",
    "Therefore, although the statistical results technically support a strong relationship, it is important to acknowledge that the underlying data is likely flawed or recorded using a simplified measure. As a result, the conclusion is influenced more by the structure of the dataset than by genuine developer performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dc98c-1d5a-4ddc-8b00-9189503c7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df_clean, x='z1000t', y='z1000mem')\n",
    "plt.xlabel(\"Runtime (min)\")\n",
    "plt.ylabel(\"Memory usage (KB)\")\n",
    "plt.title(\"Runtime vs Memory Usage (z1000 input)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac7827-000d-447f-b9f3-3a483a42919b",
   "metadata": {},
   "source": [
    "### Discussing Hypothesis One\n",
    "\n",
    "**The longer the runtime, the more memory consumption the program requires.***\n",
    "\n",
    "The statistical results do not provide evidence to support this hypothesis. Although a few outliers remain, the overall visualization and correlation analysis indicate that runtime and memory usage are not meaningfully related in this dataset. One plausible explanation is that memory usage on the systems used in this study does not act as a performance bottleneck. Modern programs often operate within efficient memory management environments, where additional memory demands do not necessarily translate into increased runtime. It is possible that under different conditions memory consumption could have a stronger effect on runtime. However, for the machines and programs examined here, this relationship does not appear to exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51b4b0-e3ef-4c2b-9a90-399954daea5e",
   "metadata": {},
   "source": [
    "### Discussing Statistical Methods\n",
    "\n",
    "**Correlation Computations**\n",
    "Pearsonâ€™s correlation coefficient was used to evaluate relationships between continuous variables. For the correlation between lines of code and working hours, a linear association was expected. The resulting perfect correlation, also visible in the Pearson correlation heatmap, was initially surprising but became clear after further examination of the data, where each subject showed a fixed ratio of one line of code per hour.\n",
    "\n",
    "For the relationship between self-rated programming capability (caps) and reliability (m1000rel), Spearmanâ€™s rank correlation was applied instead. Since caps is an ordinal variable with ranked percentage categories, Spearmanâ€™s method was more appropriate for assessing a monotonic relationship without assuming linearity.\n",
    "\n",
    "**Hypothesis Testing Methods**\n",
    "Pearsonâ€™s method was also applied for testing both hypotheses to maintain consistency in the analysis. Although the second hypothesis included some outliersâ€”which could support the use of Spearmanâ€™s rank correlation due to its robustness against extreme valuesâ€”Spearmanâ€™s method was deemed less suitable because the variables involved (runtime and memory usage) are ratio-scaled and not ordinal. Therefore, Pearsonâ€™s correlation remains a justified choice for this type of data.\n",
    "\n",
    "**Visualization Tools**\n",
    "Scatter plots were used to visualize the relationships tested in the hypotheses. This approach was particularly effective in Hypothesis 1, clearly illustrating the unrealistic nature of the perfect linear trend. Additionally, the correlation heatmap provided an intuitive overview of how multiple continuous variables relate to each other, further supporting the use of Pearsonâ€™s method throughout the study.\n",
    "\n",
    "**Other insights**\n",
    "Reflecting on the analysis doing a hypothesis test on the correlation between capability and output reliability could have deemed more intresting result since the correlation analysis already showed that subjects might have overestimate themselves in terms of reliablity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
